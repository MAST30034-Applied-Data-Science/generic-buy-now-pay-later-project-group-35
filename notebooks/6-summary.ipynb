{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f935367d-cab0-4904-9bed-676c9eccd84b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create a spark session\u001b[39;00m\n\u001b[1;32m     19\u001b[0m spark \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manalysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.repl.eagerEval.enabled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.parquet.cacheMetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.session.timeZone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEtc/UTC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.driver.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.executor.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:275\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m     session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m--> 275\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSparkSession$\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODULE$\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     )\u001b[38;5;241m.\u001b[39mapplyModifiableSettings(session\u001b[38;5;241m.\u001b[39m_jsparkSession, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1709\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m UserHelpAutoCompletion\u001b[38;5;241m.\u001b[39mKEY:\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[0;32m-> 1709\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFLECTION_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEND_COMMAND_PART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaPackage(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, jvm_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "from owslib.wfs import WebFeatureService\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sklearn\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"analysis\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.executor.memory\", \"6g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d887e8",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a71769",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb12ee",
   "metadata": {},
   "source": [
    "**Team Members:** Aryan Shahi, Jai Bretherton, Eesha Syed, Minma Herath\n",
    "\n",
    "The goal of this project and repository was to select the 100 most profitable merchants to onboard for the new pay in 5 installments plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e197b08",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0a0e8",
   "metadata": {},
   "source": [
    "**Given Data:** It was identified that the transaction dataset provided would be the primary table of interest, with all other tables then being joined to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchantdf = spark.read.parquet(\"../data/curated/merchantdf.parquet/\")\n",
    "userdf = spark.read.parquet(\"../data/tables/consumer_user_details.parquet\")\n",
    "transactiondf = spark.read.parquet(\"../data/curated/transactiondf.parquet/\")\n",
    "consumerdf = spark.read.option(\"header\",\"true\").csv(\"../data/tables/tbl_consumer.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d943ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchantdf.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af68ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "userdf.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactiondf.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5105ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumerdf.limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ebce9",
   "metadata": {},
   "source": [
    "**External**: We identifed age and income of customers as likely variables of interest. Therefore, we utilised a [population based dataset](https://www.abs.gov.au/statistics/people/population/regional-population-age-and-sex/latest-release) (containing a breakdown by age) and an [income based dataset](https://data.aurin.org.au/dataset/au-govt-abs-abs-personal-income-total-income-sa2-2011-2018-sa2-2016), both of which were for SA2 codes. We therefore additionally required a dataset to [map SA2 codes to postcodes](https://www.matthewproctor.com/australian_postcodes?simple=True).\n",
    "\n",
    "We make two key assumptions with these datasets, the first being that since a postcode can belong to multiple SA2 codes, we can estimate the income and population demographics for a postcode by taking the median value of all associated SA2 codes. Additionally, we are assuming that these median postcode statistics are representive of all customers from that postcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a73294",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationdf = pd.read_excel(\"../data/tables/population.xlsx\", sheet_name = 'Table 3', skiprows = 7)\n",
    "incomedf = spark.read.option(\"header\",\"false\").csv(\"../data/tables/datasource-AU_Govt_ABS-UoM_AURIN_DB_3abs_personal_income_total_income_sa2_2011_2018.csv\")\n",
    "postcodedf = spark.read.option(\"header\",\"true\").csv(\"../data/tables/australian_postcodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df6ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5548f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "incomedf.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2dd3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodedf.limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb3156",
   "metadata": {},
   "source": [
    "### Pre Processing and Outlier Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557ed0a4-8557-4813-8a5f-cd3cfd1bc521",
   "metadata": {},
   "source": [
    "Much more detail is provided in the relevant preprocessing and analysis notebooks, however some key findings:\n",
    "\n",
    "1. 1014 transactions in the dataset had a dollar value less than a cent, so was removed as they were clearly nonsensical\n",
    "2. Once the revenue band and take rate were extracted, the tag field after cleanup only contained 25 unique values, a fact which became useful when segmenting merchants\n",
    "3. Population dataset was given custom age groups of under 10, adolescent (aged 10-17), young adult (18-34), middle age (35-59) and old (60+)\n",
    "4. An [alternative SA2 to postcode dataset](https://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.006July%202011?OpenDocument) was considered, which additionally provided a ratio representing the proportion of the population for a given postcode that were located in the SA2 codes it made up. While this could have allowed for the use of a weighted average, this dataset contained far less records, and would have led to a loss of almost 1.5 million transactions.\n",
    "5. Only 2018 income data was used, specifically the number of earners, median age of earners, median income and mean income for all given SA2 codes.\n",
    "\n",
    "In total, our final dataset contained roughly 11,800,000 transactions, all with information about the merchant and consumer, as well as age and income demographics for the postcode the customer resided in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b765f3f-1fdc-4bf6-935e-fce1281483e8",
   "metadata": {},
   "source": [
    "### Fraud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433877ba-5a32-4039-adab-dd2bd79e390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumerfrauddf = spark.read.parquet(\"../data/curated/consumerfrauddf.parquet/\")\n",
    "merchantfrauddf = spark.read.parquet(\"../data/curated/merchantfrauddf.parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32193dac-3d49-484b-96c8-4f0e9978dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumerfrauddf.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf63634-73b1-4f58-a85e-fc3f8bc9cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchantfrauddf.limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087172de",
   "metadata": {},
   "source": [
    "We were additionally supplied with both a consumer and merchant fraud dataset. We decided that, once joined with all transactions for that merchant/user and day, any transaction with a fraud_probability greater than 1.0 (i.e all the combinations contained in the dataset) would be considered fraud and hence removed. While this likely means we removed non-fraudulent transactions, our method only removed 0.005% of transactions. Therefore, there was really no significant consequence to ensuring that we almost certainty removed all fraudulent transactions from consideration. \n",
    "\n",
    "Additionally, since we could be fairly sure that all remaining transactions were not fraudulent, we were able to determine distributions in order to assist with predicting future fraud. It was decided if a user or merchant has 1.5 times their standard deviation in the number of transactions or transaction amounts in a day, then they will be considered fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2488d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "futureuserfrauddf = spark.read.parquet(\"../data/curated/future_user_fraud.parquet\")\n",
    "futuremerchantfrauddf = spark.read.parquet(\"../data/curated/future_merchant_fraud.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7dcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "futureuserfrauddf.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce782550",
   "metadata": {},
   "outputs": [],
   "source": [
    "futuremerchantfrauddf.limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7afef08",
   "metadata": {},
   "source": [
    "This then gives us our final dataset to be used in modelling and thus ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bba4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = spark.read.parquet(\"../data/curated/finaldf.parquet/\")\n",
    "finaldf.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c0366",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e24e0-5639-4a9d-ac5a-7f38cbfceefd",
   "metadata": {},
   "source": [
    "One of our very first ideas we had for the modeling and ranking of merchants was to simply onboard the merchants that had generated the most overall revenue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b80c2-7f8b-4486-ba6f-8711c6175318",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldf1 = finaldf.withColumn(\"year\", date_format(col(\"order_datetime\"), \"yyyy\").cast(\"long\"))\n",
    "modeldf1 = modeldf1.withColumn(\"month\", date_format(col(\"order_datetime\"), \"MM\").cast(\"long\"))\n",
    "modeldf1 = modeldf1.withColumn('profit', round(finaldf.dollar_value * (finaldf.take_rate / 100), 2))\n",
    "\n",
    "for field in (\"postcode\",\"take_rate\"):\n",
    "    modeldf1 = modeldf1.withColumn(\n",
    "        field,\n",
    "        col(field).cast('double')\n",
    "    )\n",
    "\n",
    "modeldf1 = modeldf1.drop(\"order_datetime\",\"order_id\",\"company_name\",\"consumer_fraud_%\",\"merchant_fraud_%\")\n",
    "\n",
    "modeldf1 = modeldf1.groupBy(\"year\",\"month\",\"merchant_abn\").agg(\n",
    "    round(sum(\"profit\"),2).alias(\"monthly_profit\"),\n",
    ")\n",
    "modeldf1.limit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71107a21-8147-48c0-a30f-14d10488aec7",
   "metadata": {},
   "source": [
    "However, we realised that a simple approach such as this would be making the rather significant assumption that once a merchant is onboarded, every single transaction made with that merchant would now be made with the BNPL technology, which clearly isn’t a very realistic assumption.\n",
    " \n",
    "So to improve on this idea, we decided we would still use the overall revenue, but also consider two other features. In order to determine these other features, we reviewed surveys from [C+R research](https://www.crresearch.com/blog/buy_now_pay_later_statistics) as well as [Bankrate](https://www.bankrate.com/loans/personal-loans/buy-now-pay-later-statistics/) regarding BNPL usage statistics. Some interesting statistics we found was that only 3% of respondents owed over $2 500 currently to BNPL services, and this debt was owed across an average of 3.8 different purchased items. \n",
    "\n",
    "Considering the strict pay in 5 installments structure that is being imposed, we determined that there was likely to be a limit as to how much customers would spend in a single BNPL transaction. Hence we should prefer merchants who not only generated large revenue, but did so through a large number of transactions. A large number of transactions would imply that these transactions are of lesser value in general, a trait we see as desirable for the statistics above. This was the motivation behind our second feature being the number of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a5897-7a0e-4686-bbfe-a0f075d6a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldf2 = finaldf.withColumn(\"year\", date_format(col(\"order_datetime\"), \"yyyy\").cast(\"long\"))\n",
    "modeldf2 = modeldf2.withColumn(\"month\", date_format(col(\"order_datetime\"), \"MM\").cast(\"long\"))\n",
    "\n",
    "for field in (\"postcode\",\"take_rate\"):\n",
    "    modeldf2 = modeldf2.withColumn(\n",
    "        field,\n",
    "        col(field).cast('double')\n",
    "    )\n",
    "\n",
    "modeldf2 = modeldf2.drop(\"order_datetime\",\"order_id\",\"company_name\",\"consumer_fraud_%\",\"merchant_fraud_%\")\n",
    "\n",
    "modeldf2 = modeldf2.groupBy(\"year\",\"month\",\"merchant_abn\").agg(\n",
    "    count(\"dollar_value\").alias(\"monthly_transactions\"),\n",
    ")\n",
    "\n",
    "modeldf2.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff46245-4421-47c9-84a2-523d7cfff14c",
   "metadata": {},
   "source": [
    "However, by similar logic, we should also prefer merchants with a wider consumer base, or a merchant that makes a large amount of revenue, from frequent, smaller value transactions that are likely to be from different customers. Additionally, we found that amongst certain predefined income ranges, the highest proportion of BNPL users came from the group with average household income between \\\\$50 000-\\\\$75 000. Combining these two ideas led to our third feature, which was based on the number of unique customers for a given merchant who resides in a postcode with median income between \\\\$50 000 and \\\\$75 000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293386be-574f-461c-8241-6882522c970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_INCOME_THRESHOLD = 50000\n",
    "UPPER_INCOME_THRESHOLD = 75000\n",
    "modeldf3 = finaldf.withColumn(\"year\", date_format(col(\"order_datetime\"), \"yyyy\").cast(\"long\"))\n",
    "modeldf3 = modeldf3.withColumn(\"month\", date_format(col(\"order_datetime\"), \"MM\").cast(\"long\"))\n",
    "modeldf3 = modeldf3.filter((modeldf3.median_income > LOWER_INCOME_THRESHOLD) &\n",
    "                         (modeldf3.median_income < UPPER_INCOME_THRESHOLD))\n",
    "                                     \n",
    "for field in (\"postcode\",\"take_rate\"):\n",
    "    modeldf3 = modeldf3.withColumn(\n",
    "        field,\n",
    "        col(field).cast('double')\n",
    "    )\n",
    "\n",
    "modeldf3 = modeldf3.drop(\"order_datetime\",\"order_id\",\"company_name\",\"consumer_fraud_%\",\"merchant_fraud_%\")\n",
    "modeldf3 = modeldf3.groupBy(\"year\",\"month\",\"merchant_abn\").agg(\n",
    "    countDistinct(\"consumer_id\").alias(\"monthly_middle_customers\"),\n",
    ")\n",
    "modeldf3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b6bb7-a06d-40fa-9f46-a3675b0bec63",
   "metadata": {},
   "source": [
    "However, rather than just deriving these features based on the previous transactions seen in the data, we aimed to identify any potential trends in these features for merchants over time, and hence try and forecast the values of these features, for every merchant in every month of 2023. \n",
    " \n",
    "Such predictions were done through the use of a simple time series regression model, which is essentially just a typical linear regression model, but with the addition of what are called lagged variables. To take the example of our model to predict future revenue, the lagged variables in this time series regression would be the predicted revenue of the merchant for the previous certain amount of months. \n",
    "\n",
    "The models were built using data from February 2021 - July 2022, and predictions were made and compared to the actual values for August 2022 - October 2022 to ensure the validity of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9337f-1733-4af3-b9cb-07225a62fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = spark.read.parquet(\"../data/curated/trans_num_predictions.parquet\").toPandas()\n",
    "print(mean_absolute_error(dfp[\"monthly_transactions\"],  dfp[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304dc91-bde1-4a49-8fa7-e450e11213fe",
   "metadata": {},
   "source": [
    "On average, the model is incorrect by 17.27 transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e579e1a-af5a-4f24-8416-e13f1352b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = spark.read.parquet(\"../data/curated/profit_merch_predictions.parquet\").toPandas()\n",
    "print(mean_absolute_error(dfp[\"monthly_profit\"],  dfp[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf975b-78ba-4666-bf1a-c2f77e813522",
   "metadata": {},
   "source": [
    "On average, the model is incorrect by $191.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba9413-809e-4336-be46-619c13b9634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = spark.read.parquet(\"../data/curated/medium_customers_predictions.parquet\").toPandas()\n",
    "print(mean_absolute_error(dfp[\"monthly_middle_customers\"],  dfp[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aba37b-c747-4219-a46d-d20e09e55f8a",
   "metadata": {},
   "source": [
    "On average, our model is incorrect by 5.49 'middle' customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef90e0a-7e82-4ffc-a9d1-15dfc846a26c",
   "metadata": {},
   "source": [
    "Determining how many months to use to predict the next month's features was a difficult task. On one hand, having more lags means a smaller sample size of months to build our model on, as for example, the month of February 2021 doesn’t have any data from a previous month to use as a feature, meaning it is of no use to us. So the more lags we add, the more months we discard. \n",
    "\n",
    "However, more lags means our model can (to an extent) more accurately predict certain trends over time. Extended analysis (see appropriate notebooks for further analysis) determined that for a large majority of merchants, two lags was seen as being the amount which balanced these factors best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d82f527-fe3c-498c-8c6d-f9caa8b5f9ff",
   "metadata": {},
   "source": [
    "Alongside the above curated features, we determined that merchants with a relatively large population of young and middle aged adults are more desired. This was based on a research report presented by [AFIA (pg.24)](https://afia.asn.au/files/galleries/AFIA_BNPL_Research_Report.pdf) showing the BNPL Usage over time by age group, with 25-34 year olds having the highest usage, followed closely by 18-24 year olds, then 35-44 year olds, and so on. Thus, using postcode data for each merchant, we extrapolated the population of each age group using the population dataset. We then obtained the quantile values for each age group and categorized the data into the 4 quantiles as follows:\n",
    "\n",
    "* group 1 :  LowerQuartile\n",
    "* group 2 : between LowerQuatile and Median\n",
    "* group 3 : between Median and UpperQuartile\n",
    "* group 4 :  UpperQuartile\n",
    "\n",
    "This was done so comparisons between population values for a given age group would be easier, e.g. for the young adult population, having less than 022 is considered small, whereas having more than 2073 is considered very large (see notebook 4.4 to get the quantile values for each age group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f602bb-fdb6-426f-9f5c-ffb0d3113dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_pop = spark.read.parquet(\"../data/curated/merch_pop.parquet/\")\n",
    "merch_pop.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f0d50",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7033447",
   "metadata": {},
   "source": [
    "#### Initial Ranking System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b1913",
   "metadata": {},
   "source": [
    "Ranking System uses the following features:\n",
    "- future predictions for transactions per merchant per month\n",
    "- future predictions for profit per merchant per month\n",
    "- future predictions for customers within revenue range \\\\$50k-\\\\$75k per month\n",
    "- population (quartiles) of young adults and middle aged adults based on postcodes of consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe109f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_trans_sdf = spark.read.parquet(\"../data/curated/futuretrans.parquet/\")\n",
    "future_profit_sdf = spark.read.parquet(\"../data/curated/futureprofit.parquet/\")\n",
    "future_mcustomers_sdf = spark.read.parquet(\"../data/curated/futuremcustomers.parquet/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2e503",
   "metadata": {},
   "source": [
    "Create a pandas dataframe to store points for each merchant, with total points initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f02eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_points_pd = future_trans_sdf \\\n",
    "    .select('merchant_abn') \\\n",
    "    .distinct() \\\n",
    "    .withColumns({\n",
    "        'total_points': lit(1),\n",
    "        'pop_points': lit(0),\n",
    "        'trans_points': lit(0),\n",
    "        'profit_points': lit(0),\n",
    "        'mcust_points': lit(0)\n",
    "    }) \\\n",
    "    .orderBy(\"merchant_abn\") \\\n",
    "    .toPandas()\n",
    "\n",
    "merch_points_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f234a4d",
   "metadata": {},
   "source": [
    "Have 4018 distinct merchants, need to select top 100 merchants\n",
    "\n",
    "Idea:\n",
    "- all merchants have initial points 1\n",
    "- the more the number of points, the higher/better the rank will be\n",
    "- points given based on sorted positioning within the features and importance of the feature (for transaction, profit, and mcustomers)\n",
    "- award 0.125 points to merchants having a relatively large young adult and middle age population (external research) <br>\n",
    "with large meaning the populations are above the lower quartile (not group 1 - see notebook 4.4)\n",
    "- each feature has a weight to assign importance, with all weights summing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_POP = 0.125\n",
    "WEIGHT_TRANS = 0.375\n",
    "WEIGHT_PROFIT = 0.375\n",
    "WEIGHT_MCUSTOMERS = 0.125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f2c32b-461c-449d-95c2-ea197ce1097d",
   "metadata": {},
   "source": [
    "Based on the above idea, the resulting points for each merchant are as shown: (see notebook 5 for detailed implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4039b7-6a66-471f-88a7-4b11b80284d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_points_df = spark.read.parquet(\"../data/curated/merch_points.parquet\").sort(desc(\"total_points\")).toPandas()\n",
    "merch_points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34fb16-4869-4fdc-ac14-d657c0b8afcf",
   "metadata": {},
   "source": [
    "Get the top 100 merchants with rankings and associated data for each merchant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12511f-28fc-4cf1-bef2-a2d4633467ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merchant data\n",
    "merchants_sdf = spark.read.parquet(\"../data/curated/merchantdf.parquet/\")\n",
    "\n",
    "# get only the top 100 \n",
    "top100_sdf = spark.createDataFrame(merch_points_df.iloc[1:101,])\n",
    "\n",
    "# join the two\n",
    "top100_merch = merchants_sdf.join(top100_sdf, \"merchant_abn\").orderBy(desc(\"total_points\"))\n",
    "\n",
    "# get ranking\n",
    "top100_merch = top100_merch \\\n",
    "    .select(\"*\") \\\n",
    "    .withColumn(\"rank\", monotonically_increasing_id()) \\\n",
    "    .withColumn(\"rank\", col(\"rank\") + lit(1))\n",
    "    \n",
    "top100_merch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1baa7-4854-4d64-bbc6-94b090b4ab62",
   "metadata": {},
   "source": [
    "Observe frequency of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62456cd-6381-4f43-88a7-ba2f233ea0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_count = top100_merch.groupBy(\"tags\") \\\n",
    "    .agg(\n",
    "        count(\"merchant_abn\").alias(\"count\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"count\")) \\\n",
    "    .toPandas()\n",
    "\n",
    "plt.barh(tags_count[\"tags\"], tags_count[\"count\"])\n",
    "plt.xlabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb78305",
   "metadata": {},
   "source": [
    "#### Segmented Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8062776",
   "metadata": {},
   "source": [
    "Konw that we have 25 unique tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd8c79",
   "metadata": {},
   "source": [
    "Assign tags to categories as follows:\n",
    "\n",
    "**Hobbies: books, movies, music, and games**\n",
    "- artist supply and craft shops\n",
    "- books, periodicals, and newspapers\n",
    "- digital goods: books, movies, music\n",
    "- hobby, toy and game shops\n",
    "- music shops - musical instruments, pianos, and sheet music\n",
    "\n",
    "**Home and Office**\n",
    "- cable, satellite, and other pay television and radio services\n",
    "- computer programming , data processing, and integrated systems design services\n",
    "- computers, computer peripheral equipment, and software\n",
    "- equipment, tool, furniture, and appliance rent al and leasing\n",
    "- furniture, home furnishings and equipment shops, and manufacturers, except appliances\n",
    "- stationery, office supplies and printing and writing paper\n",
    "- telecom\n",
    "\n",
    "**Outdoors**\n",
    "- bicycle shops - sales and service\n",
    "- florists supplies, nursery stock, and flowers\n",
    "- lawn and garden supply outlets, including nurseries\n",
    "- motor vehicle supplies and new parts\n",
    "- tent and awning shops\n",
    "\n",
    "**Self-care and Fashion**\n",
    "- health and beauty spas\n",
    "- jewelry, watch, clock, and silverware shops\n",
    "- opticians, optical goods, and eyeglasses\n",
    "- shoe shops\n",
    "- watch, clock, and jewelry repair shops\n",
    "\n",
    "**Other**\n",
    "- antique shops - sales, repairs, and restoration services\n",
    "- art dealers and galleries\n",
    "- gift, card, novelty, and souvenir shops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc431c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store first word of every tag (know that each tag begins with a unique word)\n",
    "segments_dic = {\n",
    "    \"Hobbies\": [\"artist\", \"books\", \"digital\", \"hobby\", \"music\"],\n",
    "    \"Home and Office\": [\"cable\", \"computer\", \"computers\", \"equipment\", \"furniture\", \"stationery\", \"telecom\"],\n",
    "    \"Outdoor\": [\"bicycle\", \"florists\", \"lawn\", \"motor\", \"tent\"],\n",
    "    \"Self-care and Fashion\": [\"health\", \"jewelry\", \"opticians\", \"shoe\", \"watch\"],\n",
    "    \"Other\": [\"antique\", \"art\", \"gift\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f4ab3-2a09-4d10-bbcd-a13d0e397021",
   "metadata": {},
   "source": [
    "Need to get top 10 merchants in each segment.\n",
    "\n",
    "Following the same idea for the ranking system and noting the defined segments above, we obtain the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f7ab4-620b-48a5-8040-84de4176ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ranks_sdf = spark.read.parquet(\"../data/curated/seg_ranks.parquet\")\n",
    "seg_ranks_sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195a33e",
   "metadata": {},
   "source": [
    "Observe frequency of tags for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d505155",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ranks_df = seg_ranks.toPandas()\n",
    "seg_ranks_grp = seg_ranks_df.groupby([\"segment\"])\n",
    "\n",
    "i = 0\n",
    "for segment in segments_dic.keys():\n",
    "    top10 = seg_ranks_grp.get_group(segment)\n",
    "    tags_count = dict(Counter(top10[\"tags\"]))\n",
    "    print(tags_count)\n",
    "\n",
    "    plt.figure(i)\n",
    "    plt.title(segment)\n",
    "    plt.barh(list(tags_count.keys()), list(tags_count.values()))\n",
    "    #plt.hist(top10[\"tags\"], orientation='horizontal')\n",
    "\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
